# -*- coding: utf-8 -*-
"""proyek sentimen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Egc4OhmytjMp7RALDd2ZFyoz7dHlID-q

# 1. Scraping Data Spotify dari Google Play Store
"""

!pip install google-play-scraper

from google_play_scraper import app, reviews, Sort
import pandas as pd
import numpy as np
import time

# Scrap all review
from google_play_scraper import Sort, reviews_all

def scrape_spotify_reviews():
    result = reviews_all(
      'com.spotify.music', # ID aplikasi Spotify
       sleep_milliseconds=0, # delay untuk hindari blokir
       lang='id',
       country='id',
       sort=Sort.MOST_RELEVANT, # urutan berdasarkan relevan
       count=3000,                    #Maksimal permintaan
       filter_score_with=None # seluruh score
)
    return result

spotify_reviews_data = scrape_spotify_reviews()

df = pd.DataFrame(spotify_reviews_data)

# Filter kolom penting
df = df[['content', 'score', 'at', 'thumbsUpCount']]

# Simpan kolom yang terfilter ke CSV file
df.to_csv('spotify_reviews.csv', index=False)
print(f"Data Spotify berhasil discrape: {len(df)} ulasan")

from google.colab import files
files.download('spotify_reviews.csv')

"""# 2. Preprocessing Khusus Spotify"""

!pip install Sastrawi

from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory
import re

factory = StemmerFactory()
stemmer = factory.create_stemmer()
stop_factory = StopWordRemoverFactory()
stopword = stop_factory.create_stop_word_remover()

def preprocess_text(text):
    if not isinstance(text, str):
        return ""

    # Handling istilah musik & Spotify
    text = re.sub(r'\b(spotify|premium|lagu|musik|playlist|artis)\b', '', text, flags=re.IGNORECASE)
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)

    # Slang khusus musik
    slang_dict = {
        'lagu': 'lagu', 'playlist': 'playlist', 'skip': 'lewati',
        'shuffle': 'acak', 'repeat': 'ulang', 'album': 'album',
        'bug': 'error', 'lag': 'lambat', 'error': 'galat'
    }

    words = text.split()
    words = [slang_dict.get(word, word) for word in words]
    text = ' '.join(words)

    # Stopword removal + stemming
    text = stopword.remove(text)
    return stemmer.stem(text)

df['cleaned_text'] = df['content'].apply(preprocess_text)

# Pelabelan dengan threshold Spotify (rating 1-5)
def label_sentiment(score):
    if score >= 4:  # Spotify rata-rata rating tinggi
        return "positif"
    elif score <= 2:
        return "negatif"
    else:
        return "netral"

df['sentiment'] = df['score'].apply(label_sentiment)

# 3. Pembagian Dataset yang Valid
from sklearn.model_selection import train_test_split
from sklearn.utils import resample

# Handle class imbalance
df_pos = df[df.sentiment == 'positif']
df_neg = df[df.sentiment == 'negatif']
df_neu = df[df.sentiment == 'netral']

# Downsample majority class (positif)
df_pos_down = resample(df_pos, n_samples=len(df_neg), random_state=42)
balanced_df = pd.concat([df_pos_down, df_neg, df_neu])

X = balanced_df['cleaned_text']
y = balanced_df['sentiment']

# Encode label numerik
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_encoded = le.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42
)

# 4. Model LSTM yang Dioptimasi
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout
from tensorflow.keras.regularizers import l2

def build_spotify_model(vocab_size, max_length):
    model = Sequential([
        Embedding(
            input_dim=vocab_size,
            output_dim=128,
            input_length=max_length,
            embeddings_regularizer=l2(0.001)
        ),
        Bidirectional(LSTM(64, return_sequences=True)),
        Bidirectional(LSTM(32)),
        Dense(64, activation='relu', kernel_regularizer=l2(0.001)),
        Dropout(0.5),
        Dense(3, activation='softmax')
    ])

    model.compile(
        loss='sparse_categorical_crossentropy',
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),
        metrics=['accuracy']
    )
    return model

#5. Training dengan 3 Pendekatan (TF-IDF dihapus, fokus pada embedding)
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Tokenization
tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

# Sequence conversion
train_sequences = tokenizer.texts_to_sequences(X_train)
test_sequences = tokenizer.texts_to_sequences(X_test)

max_length = 128  # Optimal untuk review
train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')
test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')

# Bangun model
vocab_size = len(tokenizer.word_index) + 1
model = build_spotify_model(vocab_size, max_length)

# Callback untuk early stopping
from tensorflow.keras.callbacks import EarlyStopping
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Training
history = model.fit(
    train_padded, y_train,
    validation_split=0.1,
    epochs=20,
    batch_size=64,
    callbacks=[early_stop]
)

# 6. Evaluasi Komprehensif
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Prediksi dan konversi label
y_pred = model.predict(test_padded)
y_pred_classes = np.argmax(y_pred, axis=1)

# Classification report
print("LSTM Classification Report:")
print(classification_report(y_test, y_pred_classes, target_names=le.classes_))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred_classes)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_,
            yticklabels=le.classes_)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix - Spotify Reviews')
plt.savefig('spotify_confusion_matrix.png', dpi=300)

# 7. Inference Endpoint dengan Fallback
def predict_spotify_sentiment(text):
    try:
        # Preprocessing
        cleaned = preprocess_text(text)

        # Sequence conversion
        seq = tokenizer.texts_to_sequences([cleaned])
        padded = pad_sequences(seq, maxlen=max_length, padding='post', truncating='post')

        # Prediction
        prediction = model.predict(padded)
        sentiment_idx = np.argmax(prediction)

        # Confidence score
        confidence = np.max(prediction)

        return {
            'sentiment': le.inverse_transform([sentiment_idx])[0],
            'confidence': float(confidence),
            'interpretation': {
                0: 'negatif',
                1: 'netral',
                2: 'positif'
            }[sentiment_idx]
        }
    except Exception as e:
        return {'error': str(e), 'text': text}

# Contoh Inference
test_reviews = [
    "Aplikasi sering crash saat buka playlist",
    "Kualitas audio premium sangat memuaskan",
    "Update terbaru membuat pemutaran lebih lancar"
]

for review in test_reviews:
    result = predict_spotify_sentiment(review)
    print(f"Review: {review}")
    print(f"Hasil: {result}\n")